{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Make</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>AgeOfVehicle</th>\n",
       "      <th>AgeOfPolicyHolder</th>\n",
       "      <th>PoliceReportFiled</th>\n",
       "      <th>WitnessPresent</th>\n",
       "      <th>AgentType</th>\n",
       "      <th>NumberOfSuppliments</th>\n",
       "      <th>AddressChange_Claim</th>\n",
       "      <th>NumberOfCars</th>\n",
       "      <th>Year</th>\n",
       "      <th>BasePolicy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>3 years</td>\n",
       "      <td>26 to 30</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>6 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>7 years</td>\n",
       "      <td>41 to 50</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun</td>\n",
       "      <td>2</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Jul</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>more than 7</td>\n",
       "      <td>51 to 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan</td>\n",
       "      <td>5</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>5 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  WeekOfMonth  DayOfWeek    Make AccidentArea DayOfWeekClaimed  \\\n",
       "0   Dec            5  Wednesday   Honda        Urban          Tuesday   \n",
       "1   Jan            3  Wednesday   Honda        Urban           Monday   \n",
       "2   Oct            5     Friday   Honda        Urban         Thursday   \n",
       "3   Jun            2   Saturday  Toyota        Rural           Friday   \n",
       "4   Jan            5     Monday   Honda        Urban          Tuesday   \n",
       "\n",
       "  MonthClaimed  WeekOfMonthClaimed     Sex MaritalStatus  ...  AgeOfVehicle  \\\n",
       "0          Jan                   1  Female        Single  ...       3 years   \n",
       "1          Jan                   4    Male        Single  ...       6 years   \n",
       "2          Nov                   2    Male       Married  ...       7 years   \n",
       "3          Jul                   1    Male       Married  ...   more than 7   \n",
       "4          Feb                   2  Female        Single  ...       5 years   \n",
       "\n",
       "  AgeOfPolicyHolder PoliceReportFiled WitnessPresent AgentType  \\\n",
       "0          26 to 30                No             No  External   \n",
       "1          31 to 35               Yes             No  External   \n",
       "2          41 to 50                No             No  External   \n",
       "3          51 to 65               Yes             No  External   \n",
       "4          31 to 35                No             No  External   \n",
       "\n",
       "   NumberOfSuppliments  AddressChange_Claim  NumberOfCars  Year  BasePolicy  \n",
       "0                 none               1 year        3 to 4  1994   Liability  \n",
       "1                 none            no change     1 vehicle  1994   Collision  \n",
       "2                 none            no change     1 vehicle  1994   Collision  \n",
       "3          more than 5            no change     1 vehicle  1994   Liability  \n",
       "4                 none            no change     1 vehicle  1994   Collision  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15420 entries, 0 to 15419\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Month                 15420 non-null  object\n",
      " 1   WeekOfMonth           15420 non-null  int64 \n",
      " 2   DayOfWeek             15420 non-null  object\n",
      " 3   Make                  15420 non-null  object\n",
      " 4   AccidentArea          15420 non-null  object\n",
      " 5   DayOfWeekClaimed      15420 non-null  object\n",
      " 6   MonthClaimed          15420 non-null  object\n",
      " 7   WeekOfMonthClaimed    15420 non-null  int64 \n",
      " 8   Sex                   15420 non-null  object\n",
      " 9   MaritalStatus         15420 non-null  object\n",
      " 10  Age                   15420 non-null  int64 \n",
      " 11  Fault                 15420 non-null  object\n",
      " 12  PolicyType            15420 non-null  object\n",
      " 13  VehicleCategory       15420 non-null  object\n",
      " 14  VehiclePrice          15420 non-null  object\n",
      " 15  y                     15420 non-null  int64 \n",
      " 16  PolicyNumber          15420 non-null  int64 \n",
      " 17  RepNumber             15420 non-null  int64 \n",
      " 18  Deductible            15420 non-null  int64 \n",
      " 19  DriverRating          15420 non-null  int64 \n",
      " 20  Days_Policy_Accident  15420 non-null  object\n",
      " 21  Days_Policy_Claim     15420 non-null  object\n",
      " 22  PastNumberOfClaims    15420 non-null  object\n",
      " 23  AgeOfVehicle          15420 non-null  object\n",
      " 24  AgeOfPolicyHolder     15420 non-null  object\n",
      " 25  PoliceReportFiled     15420 non-null  object\n",
      " 26  WitnessPresent        15420 non-null  object\n",
      " 27  AgentType             15420 non-null  object\n",
      " 28  NumberOfSuppliments   15420 non-null  object\n",
      " 29  AddressChange_Claim   15420 non-null  object\n",
      " 30  NumberOfCars          15420 non-null  object\n",
      " 31  Year                  15420 non-null  int64 \n",
      " 32  BasePolicy            15420 non-null  object\n",
      "dtypes: int64(9), object(24)\n",
      "memory usage: 3.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('vehicle_insurance_claim_fraud.csv').rename(columns={'FraudFound_P':'y'})\n",
    "display(df.head())\n",
    "display(df.info())\n",
    "\n",
    "df_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Age</th>\n",
       "      <th>PolicyNumber</th>\n",
       "      <th>RepNumber</th>\n",
       "      <th>Deductible</th>\n",
       "      <th>DriverRating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13878.000000</td>\n",
       "      <td>13878.000000</td>\n",
       "      <td>13878.00000</td>\n",
       "      <td>13878.000000</td>\n",
       "      <td>13878.000000</td>\n",
       "      <td>13878.000000</td>\n",
       "      <td>13878.000000</td>\n",
       "      <td>13878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.789883</td>\n",
       "      <td>2.691598</td>\n",
       "      <td>39.89278</td>\n",
       "      <td>7711.645266</td>\n",
       "      <td>8.478887</td>\n",
       "      <td>407.774896</td>\n",
       "      <td>2.485084</td>\n",
       "      <td>1994.866407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.288395</td>\n",
       "      <td>1.258424</td>\n",
       "      <td>13.49240</td>\n",
       "      <td>4455.042985</td>\n",
       "      <td>4.593918</td>\n",
       "      <td>44.118755</td>\n",
       "      <td>1.120421</td>\n",
       "      <td>0.804359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>3856.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>7702.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>11584.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>15420.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WeekOfMonth  WeekOfMonthClaimed          Age  PolicyNumber  \\\n",
       "count  13878.000000        13878.000000  13878.00000  13878.000000   \n",
       "mean       2.789883            2.691598     39.89278   7711.645266   \n",
       "std        1.288395            1.258424     13.49240   4455.042985   \n",
       "min        1.000000            1.000000      0.00000      1.000000   \n",
       "25%        2.000000            2.000000     31.00000   3856.250000   \n",
       "50%        3.000000            3.000000     38.00000   7702.500000   \n",
       "75%        4.000000            4.000000     48.00000  11584.750000   \n",
       "max        5.000000            5.000000     80.00000  15420.000000   \n",
       "\n",
       "          RepNumber    Deductible  DriverRating          Year  \n",
       "count  13878.000000  13878.000000  13878.000000  13878.000000  \n",
       "mean       8.478887    407.774896      2.485084   1994.866407  \n",
       "std        4.593918     44.118755      1.120421      0.804359  \n",
       "min        1.000000    300.000000      1.000000   1994.000000  \n",
       "25%        5.000000    400.000000      1.000000   1994.000000  \n",
       "50%        8.000000    400.000000      2.000000   1995.000000  \n",
       "75%       12.000000    400.000000      3.000000   1996.000000  \n",
       "max       16.000000    700.000000      4.000000   1996.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns='y')\n",
    "y = df['y'].values.reshape(-1,1)\n",
    "\n",
    "# Show the X_train dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=.7)\n",
    "display(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14497 non-fraudulent rows, and 923 fraud rows.\n"
     ]
    }
   ],
   "source": [
    "# How balanced is the data?\n",
    "values, counts = np.unique(y, return_counts=True)\n",
    "print(f\"There are {counts[0]} non-fraudulent rows, and {counts[1]} fraud rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month    15420\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for null values, should be 15420 rows\n",
    "X.dropna().count().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the object columns, scale the numeric columns\n",
    "\n",
    "def encode_feature(dataframe, feature, Model) :\n",
    "    return pd.Series(np.ravel(Model.fit_transform(dataframe[feature].values.reshape(-1,1))), name=feature)\n",
    "\n",
    "def encode_multi(dataframe, feature, Model) :\n",
    "    encoder = Model.fit(dataframe[feature].values.reshape(-1, 1))\n",
    "    return pd.DataFrame(encoder.transform(dataframe[feature].values.reshape(-1, 1)), columns=OneHotColumnNames(feature, encoder))\n",
    "\n",
    "def OneHotColumnNames(feature, column) : \n",
    "    column_names = column.get_feature_names_out()\n",
    "    output = []\n",
    "    for column_name in column_names : \n",
    "        output.append(feature+\" \"+column_name)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fraud_data( unencoded_dataframe ) :\n",
    "\n",
    "    ORD = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    SSC = StandardScaler()\n",
    "    OHE = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    output = pd.DataFrame()\n",
    "\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"Month\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"WeekOfMonth\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"DayOfWeek\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Make\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"AccidentArea\", OHE)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_feature(unencoded_dataframe, \"DayOfWeekClaimed\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"MonthClaimed\", ORD)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_feature(unencoded_dataframe, \"WeekOfMonthClaimed\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Sex\", OHE)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_multi(unencoded_dataframe, \"MaritalStatus\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"Age\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Fault\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"PolicyType\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"VehicleCategory\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"VehiclePrice\", ORD)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_multi(unencoded_dataframe, \"RepNumber\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"Deductible\", SSC)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_feature(unencoded_dataframe, \"DriverRating\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Days_Policy_Accident\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Days_Policy_Claim\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"PastNumberOfClaims\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"AgeOfVehicle\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"AgeOfPolicyHolder\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"PoliceReportFiled\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"WitnessPresent\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"AgentType\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"NumberOfSuppliments\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"AddressChange_Claim\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"NumberOfCars\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"Year\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"BasePolicy\", OHE)], axis=\"columns\")\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the data\n",
    "X_train_encoded = pd.DataFrame()\n",
    "X_train_encoded = encode_fraud_data(X_train)\n",
    "X_test_encoded = encode_fraud_data(X_test)\n",
    "\n",
    "# Sometimes the train and test columns don't quite match up because of the \n",
    "# extra columns generated after a OneHotEncoding, so I have to do this to get \n",
    "# them to match.\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns)\n",
    "X_test_encoded = X_test_encoded.fillna(0)\n",
    "\n",
    "# Flatten the y series out.  It's already \"encoded\" because its just 1 or 0.\n",
    "y_train_flattened = np.ravel(y_train)\n",
    "y_test_flattened = np.ravel(y_test)\n",
    "\n",
    "# Write the encoded data to CSV files for later use\n",
    "X_train_encoded.to_csv(\"encoded_training_data.csv\", index=False, header=False)\n",
    "X_test_encoded.to_csv(\"encoded_test_data.csv\", index=False, header=False)\n",
    "pd.DataFrame(y_train).to_csv(\"encoded_training_fraud_scoring.csv\", index=False, header=False)\n",
    "pd.DataFrame(y_test).to_csv(\"encoded_test_fraud_scoring.csv\", index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Correlation to Determine Valuable Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Days_Policy_Accident x0_15 to 30     0.000325\n",
       "Make x0_Toyota                       0.000554\n",
       "Make x0_BMW                          0.000896\n",
       "Days_Policy_Accident x0_1 to 7       0.001470\n",
       "PolicyType x0_Sport - Liability      0.002032\n",
       "Days_Policy_Claim x0_none            0.002032\n",
       "Make x0_Lexus                        0.002032\n",
       "Make x0_Ferrari                      0.002874\n",
       "Make x0_Mercury                      0.003855\n",
       "Make x0_Porche                       0.004544\n",
       "Make x0_Nisson                       0.004937\n",
       "Make x0_Jaguar                       0.004978\n",
       "PastNumberOfClaims x0_1              0.005267\n",
       "Make x0_Chevrolet                    0.005807\n",
       "PolicyType x0_Utility - Collision    0.007471\n",
       "Days_Policy_Accident x0_8 to 15      0.007832\n",
       "Make x0_Honda                        0.008040\n",
       "WitnessPresent x0_No                 0.008057\n",
       "WitnessPresent x0_Yes                0.008057\n",
       "Month                                0.008670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = encode_fraud_data(df).corrwith(df[\"y\"]).abs().sort_values(ascending=True)\n",
    "corr_matrix.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After using SMOTE balancing, there are 13038 non-fraudulent rows, and 13038 fraud rows.\n",
      "After using CNN balancing, there are 2821 non-fraudulent rows, and 840 fraud rows.\n",
      "After using SMOTETomek Hybrid balancing, there are 13035 non-fraudulent rows, and 13035 fraud rows.\n"
     ]
    }
   ],
   "source": [
    "# Now we need to balance the datasets\n",
    "\n",
    "# Oversampling: Apply SMOTE to the training data to expand the fraud cases\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_encoded, y_train_flattened)\n",
    "\n",
    "# Undersampling: Condensed Nearest Neighbor (CNN) uses a K-nearest neighbors (KNN) \n",
    "# approach to retain samples that are necessary for the classification decision, \n",
    "# and removes samples that are correctly classified by their K-nearest neighbors.\n",
    "CNN = CondensedNearestNeighbour()\n",
    "X_train_CNN, y_train_CNN = CNN.fit_resample(X_train_encoded, y_train_flattened)\n",
    "\n",
    "# Hybrid Sampling: SMOTETomek - the combination of both methods above\n",
    "smote_tomek = SMOTETomek()\n",
    "X_train_smote_tomek, y_train_smote_tomek = smote_tomek.fit_resample(X_train_encoded, y_train_flattened)\n",
    "\n",
    "# How balanced is the data?\n",
    "values, counts = np.unique(y_train_smote, return_counts=True)\n",
    "print(f\"After using SMOTE balancing, there are {counts[0]} non-fraudulent rows, and {counts[1]} fraud rows.\")\n",
    "values, counts = np.unique(y_train_CNN, return_counts=True)\n",
    "print(f\"After using CNN balancing, there are {counts[0]} non-fraudulent rows, and {counts[1]} fraud rows.\")\n",
    "values, counts = np.unique(y_train_smote_tomek, return_counts=True)\n",
    "print(f\"After using SMOTETomek Hybrid balancing, there are {counts[0]} non-fraudulent rows, and {counts[1]} fraud rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the unbalanced data through the models for performance reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1459\n",
      "           1       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.95      1542\n",
      "   macro avg       0.47      0.50      0.49      1542\n",
      "weighted avg       0.90      0.95      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1459\n",
      "           1       0.08      0.01      0.02        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.51      0.50      0.49      1542\n",
      "weighted avg       0.90      0.94      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1459\n",
      "           1       0.17      0.24      0.20        83\n",
      "\n",
      "    accuracy                           0.90      1542\n",
      "   macro avg       0.56      0.59      0.57      1542\n",
      "weighted avg       0.91      0.90      0.90      1542\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1459\n",
      "           1       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.95      1542\n",
      "   macro avg       0.47      0.50      0.49      1542\n",
      "weighted avg       0.90      0.95      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1459\n",
      "           1       0.17      0.01      0.02        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.56      0.50      0.50      1542\n",
      "weighted avg       0.90      0.94      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1459\n",
      "           1       0.80      0.05      0.09        83\n",
      "\n",
      "    accuracy                           0.95      1542\n",
      "   macro avg       0.87      0.52      0.53      1542\n",
      "weighted avg       0.94      0.95      0.93      1542\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1459\n",
      "           1       0.08      0.01      0.02        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.51      0.50      0.49      1542\n",
      "weighted avg       0.90      0.94      0.92      1542\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Models = [SVC(kernel='poly'), \n",
    "          KNeighborsClassifier(),\n",
    "          DecisionTreeClassifier(),\n",
    "          RandomForestClassifier(),\n",
    "          ExtraTreesClassifier(),\n",
    "          GradientBoostingClassifier(),\n",
    "          AdaBoostClassifier()]\n",
    "\n",
    "for Model in Models :\n",
    "    \n",
    "    model_unbalanced = Model.fit(X_train_encoded, y_train_flattened)\n",
    "    y_pred_unbalanced = model_unbalanced.predict(X_test_encoded)\n",
    "    print(f\"{type(Model)} - No Balancing\")\n",
    "    print(\"==========================================================\")\n",
    "    print()    \n",
    "    print(classification_report(y_test_flattened, y_pred_unbalanced, labels=[0,1]))\n",
    "    print()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models with SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77      1459\n",
      "           1       0.12      0.90      0.21        83\n",
      "\n",
      "    accuracy                           0.64      1542\n",
      "   macro avg       0.56      0.77      0.49      1542\n",
      "weighted avg       0.94      0.64      0.74      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82      1459\n",
      "           1       0.10      0.57      0.17        83\n",
      "\n",
      "    accuracy                           0.71      1542\n",
      "   macro avg       0.53      0.64      0.50      1542\n",
      "weighted avg       0.92      0.71      0.79      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1459\n",
      "           1       0.18      0.23      0.20        83\n",
      "\n",
      "    accuracy                           0.90      1542\n",
      "   macro avg       0.57      0.59      0.58      1542\n",
      "weighted avg       0.91      0.90      0.91      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1459\n",
      "           1       0.11      0.01      0.02        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.53      0.50      0.50      1542\n",
      "weighted avg       0.90      0.94      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1459\n",
      "           1       0.21      0.04      0.06        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.58      0.51      0.52      1542\n",
      "weighted avg       0.91      0.94      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      1459\n",
      "           1       0.14      0.37      0.20        83\n",
      "\n",
      "    accuracy                           0.84      1542\n",
      "   macro avg       0.55      0.62      0.56      1542\n",
      "weighted avg       0.92      0.84      0.87      1542\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      1459\n",
      "           1       0.13      0.39      0.19        83\n",
      "\n",
      "    accuracy                           0.83      1542\n",
      "   macro avg       0.54      0.62      0.55      1542\n",
      "weighted avg       0.92      0.83      0.86      1542\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for Model in Models :\n",
    "\n",
    "    model_smote = Model.fit(X_train_smote, y_train_smote)\n",
    "    y_pred_smote = model_smote.predict(X_test_encoded)\n",
    "    print(f\"{type(Model)} - SMOTE Oversampling\")\n",
    "    print(\"==========================================================\")\n",
    "    print()    \n",
    "    print(classification_report(y_test_flattened, y_pred_smote, labels=[0,1]))\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models with CNN Links Undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1459\n",
      "           1       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.95      1542\n",
      "   macro avg       0.47      0.50      0.49      1542\n",
      "weighted avg       0.90      0.95      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1459\n",
      "           1       0.13      0.14      0.14        83\n",
      "\n",
      "    accuracy                           0.90      1542\n",
      "   macro avg       0.54      0.55      0.54      1542\n",
      "weighted avg       0.91      0.90      0.91      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      1459\n",
      "           1       0.11      0.29      0.15        83\n",
      "\n",
      "    accuracy                           0.83      1542\n",
      "   macro avg       0.53      0.57      0.53      1542\n",
      "weighted avg       0.91      0.83      0.86      1542\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1459\n",
      "           1       0.42      0.13      0.20        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.69      0.56      0.59      1542\n",
      "weighted avg       0.92      0.94      0.93      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1459\n",
      "           1       0.21      0.10      0.13        83\n",
      "\n",
      "    accuracy                           0.93      1542\n",
      "   macro avg       0.58      0.54      0.55      1542\n",
      "weighted avg       0.91      0.93      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1459\n",
      "           1       0.56      0.12      0.20        83\n",
      "\n",
      "    accuracy                           0.95      1542\n",
      "   macro avg       0.75      0.56      0.59      1542\n",
      "weighted avg       0.93      0.95      0.93      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1459\n",
      "           1       0.10      0.02      0.04        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.52      0.51      0.50      1542\n",
      "weighted avg       0.90      0.94      0.92      1542\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for Model in Models :\n",
    "\n",
    "    model_CNN = Model.fit(X_train_CNN, y_train_CNN)\n",
    "    y_pred_CNN = model_CNN.predict(X_test_encoded)\n",
    "    print(f\"{type(Model)} - CNN Undersampling\")\n",
    "    print(\"==========================================================\")\n",
    "    print()    \n",
    "    print(classification_report(y_test_flattened, y_pred_CNN, labels=[0,1]))\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models with SMOTETomek Hybrid Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77      1459\n",
      "           1       0.12      0.90      0.22        83\n",
      "\n",
      "    accuracy                           0.65      1542\n",
      "   macro avg       0.56      0.77      0.49      1542\n",
      "weighted avg       0.94      0.65      0.74      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83      1459\n",
      "           1       0.11      0.60      0.18        83\n",
      "\n",
      "    accuracy                           0.71      1542\n",
      "   macro avg       0.54      0.66      0.50      1542\n",
      "weighted avg       0.92      0.71      0.79      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1459\n",
      "           1       0.18      0.25      0.21        83\n",
      "\n",
      "    accuracy                           0.90      1542\n",
      "   macro avg       0.57      0.59      0.58      1542\n",
      "weighted avg       0.91      0.90      0.91      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1459\n",
      "           1       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.47      0.50      0.49      1542\n",
      "weighted avg       0.90      0.94      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1459\n",
      "           1       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.94      1542\n",
      "   macro avg       0.47      0.50      0.48      1542\n",
      "weighted avg       0.89      0.94      0.92      1542\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      1459\n",
      "           1       0.15      0.39      0.22        83\n",
      "\n",
      "    accuracy                           0.85      1542\n",
      "   macro avg       0.56      0.63      0.57      1542\n",
      "weighted avg       0.92      0.85      0.88      1542\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      1459\n",
      "           1       0.13      0.34      0.18        83\n",
      "\n",
      "    accuracy                           0.84      1542\n",
      "   macro avg       0.54      0.60      0.55      1542\n",
      "weighted avg       0.91      0.84      0.87      1542\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for Model in Models :\n",
    "\n",
    "    model_smote_tomek = Model.fit(X_train_smote_tomek, y_train_smote_tomek)\n",
    "    y_pred_smote_tomek = model_smote_tomek.predict(X_test_encoded)\n",
    "\n",
    "    print(f\"{type(Model)} - SMOTETomek Hybrid Balancing\")\n",
    "    print(\"==========================================================\")\n",
    "    print()    \n",
    "    print(classification_report(y_test_flattened, y_pred_smote_tomek, labels=[0,1]))\n",
    "    print()    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
