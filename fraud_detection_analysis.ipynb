{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Make</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>AgeOfVehicle</th>\n",
       "      <th>AgeOfPolicyHolder</th>\n",
       "      <th>PoliceReportFiled</th>\n",
       "      <th>WitnessPresent</th>\n",
       "      <th>AgentType</th>\n",
       "      <th>NumberOfSuppliments</th>\n",
       "      <th>AddressChange_Claim</th>\n",
       "      <th>NumberOfCars</th>\n",
       "      <th>Year</th>\n",
       "      <th>BasePolicy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>3 years</td>\n",
       "      <td>26 to 30</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>6 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>7 years</td>\n",
       "      <td>41 to 50</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun</td>\n",
       "      <td>2</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Jul</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>more than 7</td>\n",
       "      <td>51 to 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan</td>\n",
       "      <td>5</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>5 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  WeekOfMonth  DayOfWeek    Make AccidentArea DayOfWeekClaimed  \\\n",
       "0   Dec            5  Wednesday   Honda        Urban          Tuesday   \n",
       "1   Jan            3  Wednesday   Honda        Urban           Monday   \n",
       "2   Oct            5     Friday   Honda        Urban         Thursday   \n",
       "3   Jun            2   Saturday  Toyota        Rural           Friday   \n",
       "4   Jan            5     Monday   Honda        Urban          Tuesday   \n",
       "\n",
       "  MonthClaimed  WeekOfMonthClaimed     Sex MaritalStatus  ...  AgeOfVehicle  \\\n",
       "0          Jan                   1  Female        Single  ...       3 years   \n",
       "1          Jan                   4    Male        Single  ...       6 years   \n",
       "2          Nov                   2    Male       Married  ...       7 years   \n",
       "3          Jul                   1    Male       Married  ...   more than 7   \n",
       "4          Feb                   2  Female        Single  ...       5 years   \n",
       "\n",
       "  AgeOfPolicyHolder PoliceReportFiled WitnessPresent AgentType  \\\n",
       "0          26 to 30                No             No  External   \n",
       "1          31 to 35               Yes             No  External   \n",
       "2          41 to 50                No             No  External   \n",
       "3          51 to 65               Yes             No  External   \n",
       "4          31 to 35                No             No  External   \n",
       "\n",
       "   NumberOfSuppliments  AddressChange_Claim  NumberOfCars  Year  BasePolicy  \n",
       "0                 none               1 year        3 to 4  1994   Liability  \n",
       "1                 none            no change     1 vehicle  1994   Collision  \n",
       "2                 none            no change     1 vehicle  1994   Collision  \n",
       "3          more than 5            no change     1 vehicle  1994   Liability  \n",
       "4                 none            no change     1 vehicle  1994   Collision  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15420 entries, 0 to 15419\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Month                 15420 non-null  object\n",
      " 1   WeekOfMonth           15420 non-null  int64 \n",
      " 2   DayOfWeek             15420 non-null  object\n",
      " 3   Make                  15420 non-null  object\n",
      " 4   AccidentArea          15420 non-null  object\n",
      " 5   DayOfWeekClaimed      15420 non-null  object\n",
      " 6   MonthClaimed          15420 non-null  object\n",
      " 7   WeekOfMonthClaimed    15420 non-null  int64 \n",
      " 8   Sex                   15420 non-null  object\n",
      " 9   MaritalStatus         15420 non-null  object\n",
      " 10  Age                   15420 non-null  int64 \n",
      " 11  Fault                 15420 non-null  object\n",
      " 12  PolicyType            15420 non-null  object\n",
      " 13  VehicleCategory       15420 non-null  object\n",
      " 14  VehiclePrice          15420 non-null  object\n",
      " 15  y                     15420 non-null  int64 \n",
      " 16  PolicyNumber          15420 non-null  int64 \n",
      " 17  RepNumber             15420 non-null  int64 \n",
      " 18  Deductible            15420 non-null  int64 \n",
      " 19  DriverRating          15420 non-null  int64 \n",
      " 20  Days_Policy_Accident  15420 non-null  object\n",
      " 21  Days_Policy_Claim     15420 non-null  object\n",
      " 22  PastNumberOfClaims    15420 non-null  object\n",
      " 23  AgeOfVehicle          15420 non-null  object\n",
      " 24  AgeOfPolicyHolder     15420 non-null  object\n",
      " 25  PoliceReportFiled     15420 non-null  object\n",
      " 26  WitnessPresent        15420 non-null  object\n",
      " 27  AgentType             15420 non-null  object\n",
      " 28  NumberOfSuppliments   15420 non-null  object\n",
      " 29  AddressChange_Claim   15420 non-null  object\n",
      " 30  NumberOfCars          15420 non-null  object\n",
      " 31  Year                  15420 non-null  int64 \n",
      " 32  BasePolicy            15420 non-null  object\n",
      "dtypes: int64(9), object(24)\n",
      "memory usage: 3.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('data/vehicle_insurance_claim_fraud.csv').rename(columns={'FraudFound_P':'y'})\n",
    "display(df.head())\n",
    "display(df.info())\n",
    "\n",
    "df_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Age</th>\n",
       "      <th>PolicyNumber</th>\n",
       "      <th>RepNumber</th>\n",
       "      <th>Deductible</th>\n",
       "      <th>DriverRating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10794.000000</td>\n",
       "      <td>10794.000000</td>\n",
       "      <td>10794.000000</td>\n",
       "      <td>10794.000000</td>\n",
       "      <td>10794.000000</td>\n",
       "      <td>10794.000000</td>\n",
       "      <td>10794.000000</td>\n",
       "      <td>10794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.798684</td>\n",
       "      <td>2.704465</td>\n",
       "      <td>39.937558</td>\n",
       "      <td>7650.066241</td>\n",
       "      <td>8.497869</td>\n",
       "      <td>407.615342</td>\n",
       "      <td>2.492218</td>\n",
       "      <td>1994.856772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.287301</td>\n",
       "      <td>1.262067</td>\n",
       "      <td>13.638684</td>\n",
       "      <td>4436.368070</td>\n",
       "      <td>4.603489</td>\n",
       "      <td>43.490377</td>\n",
       "      <td>1.122029</td>\n",
       "      <td>0.800987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3791.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>7610.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>11478.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>15420.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WeekOfMonth  WeekOfMonthClaimed           Age  PolicyNumber  \\\n",
       "count  10794.000000        10794.000000  10794.000000  10794.000000   \n",
       "mean       2.798684            2.704465     39.937558   7650.066241   \n",
       "std        1.287301            1.262067     13.638684   4436.368070   \n",
       "min        1.000000            1.000000      0.000000      2.000000   \n",
       "25%        2.000000            2.000000     31.000000   3791.250000   \n",
       "50%        3.000000            3.000000     38.000000   7610.500000   \n",
       "75%        4.000000            4.000000     49.000000  11478.500000   \n",
       "max        5.000000            5.000000     80.000000  15420.000000   \n",
       "\n",
       "          RepNumber    Deductible  DriverRating          Year  \n",
       "count  10794.000000  10794.000000  10794.000000  10794.000000  \n",
       "mean       8.497869    407.615342      2.492218   1994.856772  \n",
       "std        4.603489     43.490377      1.122029      0.800987  \n",
       "min        1.000000    300.000000      1.000000   1994.000000  \n",
       "25%        5.000000    400.000000      1.000000   1994.000000  \n",
       "50%        8.000000    400.000000      3.000000   1995.000000  \n",
       "75%       12.000000    400.000000      3.000000   1996.000000  \n",
       "max       16.000000    700.000000      4.000000   1996.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns='y')\n",
    "y = df['y'].values.reshape(-1,1)\n",
    "\n",
    "# Show the X_train dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=.7)\n",
    "display(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14497 non-fraudulent rows, and 923 fraud rows.\n"
     ]
    }
   ],
   "source": [
    "# How balanced is the data?\n",
    "values, counts = np.unique(y, return_counts=True)\n",
    "print(f\"There are {counts[0]} non-fraudulent rows, and {counts[1]} fraud rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month    15420\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for null values, should be 15420 rows\n",
    "X.dropna().count().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the Data\n",
    "### We originally attempted to use an open-source encoding pipeline called DataMapper, but trying to correct the output of DataMapper proved to be far more work than writing our own encoding pipeline that exactly suited our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the object columns, scale the numeric columns\n",
    "\n",
    "def encode_feature(dataframe, feature, Model) :\n",
    "    return pd.Series(np.ravel(Model.fit_transform(dataframe[feature].values.reshape(-1,1))), name=feature)\n",
    "\n",
    "def encode_multi(dataframe, feature, Model) :\n",
    "    encoder = Model.fit(dataframe[feature].values.reshape(-1, 1))\n",
    "    return pd.DataFrame(encoder.transform(dataframe[feature].values.reshape(-1, 1)), columns=OneHotColumnNames(feature, encoder))\n",
    "\n",
    "def OneHotColumnNames(feature, column) : \n",
    "    column_names = column.get_feature_names_out()\n",
    "    output = []\n",
    "    for column_name in column_names : \n",
    "        output.append(feature+\" \"+column_name)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fraud_data( unencoded_dataframe ) :\n",
    "\n",
    "    ORD = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    SSC = StandardScaler()\n",
    "    OHE = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    output = pd.DataFrame()\n",
    "\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"Month\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"WeekOfMonth\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"DayOfWeek\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Make\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"AccidentArea\", OHE)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_feature(unencoded_dataframe, \"DayOfWeekClaimed\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"MonthClaimed\", ORD)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_feature(unencoded_dataframe, \"WeekOfMonthClaimed\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Sex\", OHE)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_multi(unencoded_dataframe, \"MaritalStatus\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"Age\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Fault\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"PolicyType\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"VehicleCategory\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"VehiclePrice\", ORD)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_multi(unencoded_dataframe, \"RepNumber\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"Deductible\", SSC)], axis=\"columns\")\n",
    "    #output = pd.concat([output, encode_feature(unencoded_dataframe, \"DriverRating\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Days_Policy_Accident\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"Days_Policy_Claim\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"PastNumberOfClaims\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"AgeOfVehicle\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"AgeOfPolicyHolder\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"PoliceReportFiled\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"WitnessPresent\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"AgentType\", OHE)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"NumberOfSuppliments\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"AddressChange_Claim\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"NumberOfCars\", ORD)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_feature(unencoded_dataframe, \"Year\", SSC)], axis=\"columns\")\n",
    "    output = pd.concat([output, encode_multi(unencoded_dataframe, \"BasePolicy\", OHE)], axis=\"columns\")\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the data\n",
    "X_train_encoded = pd.DataFrame()\n",
    "X_train_encoded = encode_fraud_data(X_train)\n",
    "X_test_encoded = encode_fraud_data(X_test)\n",
    "\n",
    "# Sometimes the train and test columns don't quite match up because of the \n",
    "# extra columns generated after a OneHotEncoding, so I have to do this to get \n",
    "# them to match.\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns)\n",
    "X_test_encoded = X_test_encoded.fillna(0)\n",
    "\n",
    "# Flatten the y series out.  It's already \"encoded\" because its just 1 or 0.\n",
    "y_train_flattened = np.ravel(y_train)\n",
    "y_test_flattened = np.ravel(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Correlation to Determine Valuable Features\n",
    "### The code below was a very iterative process of trial and error, finding features that seemed to have a very low correlation score, removing them, and then retesting the various models and balancing strategies until we felt we had a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Days_Policy_Accident x0_15 to 30     0.000325\n",
       "Make x0_Toyota                       0.000554\n",
       "Make x0_BMW                          0.000896\n",
       "Days_Policy_Accident x0_1 to 7       0.001470\n",
       "PolicyType x0_Sport - Liability      0.002032\n",
       "Days_Policy_Claim x0_none            0.002032\n",
       "Make x0_Lexus                        0.002032\n",
       "Make x0_Ferrari                      0.002874\n",
       "Make x0_Mercury                      0.003855\n",
       "Make x0_Porche                       0.004544\n",
       "Make x0_Nisson                       0.004937\n",
       "Make x0_Jaguar                       0.004978\n",
       "PastNumberOfClaims x0_1              0.005267\n",
       "Make x0_Chevrolet                    0.005807\n",
       "PolicyType x0_Utility - Collision    0.007471\n",
       "Days_Policy_Accident x0_8 to 15      0.007832\n",
       "Make x0_Honda                        0.008040\n",
       "WitnessPresent x0_No                 0.008057\n",
       "WitnessPresent x0_Yes                0.008057\n",
       "Month                                0.008670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = encode_fraud_data(df).corrwith(df[\"y\"]).abs().sort_values(ascending=True)\n",
    "corr_matrix.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the Datasets\n",
    "### Though we only show one balancing method per category (Oversampling, Undersampling, Hybrid Sampling), what is not reflected is the other attempts at different balancing strategies.  For example, at one point we tried TomekLinks undersampling, which is what lead us to SmoteTomek hybrid sampling.  Ultimately, the sampling methods chosen below are what worked best for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After using SMOTE balancing, there are 10131 non-fraudulent rows, and 10131 fraud rows.\n",
      "After using CNN balancing, there are 2210 non-fraudulent rows, and 663 fraud rows.\n",
      "After using SMOTETomek Hybrid balancing, there are 10130 non-fraudulent rows, and 10130 fraud rows.\n"
     ]
    }
   ],
   "source": [
    "# Now we need to balance the datasets\n",
    "\n",
    "# Oversampling: Apply SMOTE to the training data to expand the fraud cases\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_encoded, y_train_flattened)\n",
    "\n",
    "# Undersampling: Condensed Nearest Neighbor (CNN) uses a K-nearest neighbors (KNN) \n",
    "# approach to retain samples that are necessary for the classification decision, \n",
    "# and removes samples that are correctly classified by their K-nearest neighbors.\n",
    "CNN = CondensedNearestNeighbour()\n",
    "X_train_CNN, y_train_CNN = CNN.fit_resample(X_train_encoded, y_train_flattened)\n",
    "\n",
    "# Hybrid Sampling: SMOTETomek - the combination of both methods above\n",
    "smote_tomek = SMOTETomek()\n",
    "X_train_smote_tomek, y_train_smote_tomek = smote_tomek.fit_resample(X_train_encoded, y_train_flattened)\n",
    "\n",
    "# How balanced is the data?\n",
    "values, counts = np.unique(y_train_smote, return_counts=True)\n",
    "print(f\"After using SMOTE balancing, there are {counts[0]} non-fraudulent rows, and {counts[1]} fraud rows.\")\n",
    "values, counts = np.unique(y_train_CNN, return_counts=True)\n",
    "print(f\"After using CNN balancing, there are {counts[0]} non-fraudulent rows, and {counts[1]} fraud rows.\")\n",
    "values, counts = np.unique(y_train_smote_tomek, return_counts=True)\n",
    "print(f\"After using SMOTETomek Hybrid balancing, there are {counts[0]} non-fraudulent rows, and {counts[1]} fraud rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model Analysis - Classification\n",
    "### We decided the easiest method of choosing the right model was to iteratively test several at one time and compare the results.  We chose the seven models below to test, which we felt provided a satisfactory range of different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Models with No Balancing\n",
    "### This is the \"control test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Models = [SVC(kernel='poly'), \n",
    "          KNeighborsClassifier(),\n",
    "          DecisionTreeClassifier(),\n",
    "          RandomForestClassifier(),\n",
    "          ExtraTreesClassifier(),\n",
    "          GradientBoostingClassifier(),\n",
    "          AdaBoostClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4366\n",
      "           1       0.00      0.00      0.00       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.47      0.50      0.49      4626\n",
      "weighted avg       0.89      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4366\n",
      "           1       0.13      0.01      0.02       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.54      0.50      0.50      4626\n",
      "weighted avg       0.90      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      4366\n",
      "           1       0.18      0.21      0.19       260\n",
      "\n",
      "    accuracy                           0.90      4626\n",
      "   macro avg       0.56      0.57      0.57      4626\n",
      "weighted avg       0.91      0.90      0.90      4626\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4366\n",
      "           1       0.56      0.02      0.04       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.75      0.51      0.50      4626\n",
      "weighted avg       0.92      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      4366\n",
      "           1       0.24      0.03      0.05       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.59      0.51      0.51      4626\n",
      "weighted avg       0.91      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4366\n",
      "           1       1.00      0.03      0.05       260\n",
      "\n",
      "    accuracy                           0.95      4626\n",
      "   macro avg       0.97      0.51      0.51      4626\n",
      "weighted avg       0.95      0.95      0.92      4626\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - No Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      4366\n",
      "           1       0.15      0.02      0.03       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.55      0.51      0.50      4626\n",
      "weighted avg       0.90      0.94      0.92      4626\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for Model in Models :\n",
    "    \n",
    "    model_unbalanced = Model.fit(X_train_encoded, y_train_flattened)\n",
    "    y_pred_unbalanced = model_unbalanced.predict(X_test_encoded)\n",
    "    print(f\"{type(Model)} - No Balancing\")\n",
    "    print(\"==========================================================\")\n",
    "    print()    \n",
    "    print(classification_report(y_test_flattened, y_pred_unbalanced, labels=[0,1]))\n",
    "    print()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models with SMOTE Oversampling\n",
    "### Oversampling made the most sense to us after going through the interations, because fraud data is notoriously unbalanced, and by using undersampling, we're providing MORE data to the model for training, whereas undersampling causes a dramatic reduction in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.62      0.76      4366\n",
      "           1       0.12      0.91      0.22       260\n",
      "\n",
      "    accuracy                           0.63      4626\n",
      "   macro avg       0.56      0.76      0.49      4626\n",
      "weighted avg       0.94      0.63      0.73      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83      4366\n",
      "           1       0.09      0.47      0.15       260\n",
      "\n",
      "    accuracy                           0.71      4626\n",
      "   macro avg       0.53      0.60      0.49      4626\n",
      "weighted avg       0.91      0.71      0.79      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      4366\n",
      "           1       0.13      0.24      0.17       260\n",
      "\n",
      "    accuracy                           0.87      4626\n",
      "   macro avg       0.54      0.57      0.55      4626\n",
      "weighted avg       0.91      0.87      0.89      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4366\n",
      "           1       0.19      0.03      0.05       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.57      0.51      0.51      4626\n",
      "weighted avg       0.90      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4366\n",
      "           1       0.26      0.05      0.09       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.61      0.52      0.53      4626\n",
      "weighted avg       0.91      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88      4366\n",
      "           1       0.15      0.60      0.24       260\n",
      "\n",
      "    accuracy                           0.79      4626\n",
      "   macro avg       0.56      0.70      0.56      4626\n",
      "weighted avg       0.93      0.79      0.84      4626\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - SMOTE Oversampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      4366\n",
      "           1       0.15      0.40      0.22       260\n",
      "\n",
      "    accuracy                           0.84      4626\n",
      "   macro avg       0.56      0.63      0.57      4626\n",
      "weighted avg       0.92      0.84      0.87      4626\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for Model in Models :\n",
    "\n",
    "    model_smote = Model.fit(X_train_smote, y_train_smote)\n",
    "    y_pred_smote = model_smote.predict(X_test_encoded)\n",
    "    print(f\"{type(Model)} - SMOTE Oversampling\")\n",
    "    print(\"==========================================================\")\n",
    "    print()    \n",
    "    print(classification_report(y_test_flattened, y_pred_smote, labels=[0,1]))\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models with CNN Links Undersampling\n",
    "### Despite our reservations around fraud data and undersampling, we felt it was best to test our expectations, for the sake of completeness.  As expected, Undersampling did not deliver adequte results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4366\n",
      "           1       0.00      0.00      0.00       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.47      0.50      0.49      4626\n",
      "weighted avg       0.89      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      4366\n",
      "           1       0.12      0.10      0.11       260\n",
      "\n",
      "    accuracy                           0.91      4626\n",
      "   macro avg       0.53      0.53      0.53      4626\n",
      "weighted avg       0.90      0.91      0.90      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      4366\n",
      "           1       0.13      0.37      0.19       260\n",
      "\n",
      "    accuracy                           0.82      4626\n",
      "   macro avg       0.54      0.61      0.55      4626\n",
      "weighted avg       0.91      0.82      0.86      4626\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4366\n",
      "           1       0.33      0.10      0.16       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.64      0.55      0.56      4626\n",
      "weighted avg       0.91      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      4366\n",
      "           1       0.21      0.17      0.18       260\n",
      "\n",
      "    accuracy                           0.92      4626\n",
      "   macro avg       0.58      0.56      0.57      4626\n",
      "weighted avg       0.91      0.92      0.91      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4366\n",
      "           1       0.25      0.07      0.11       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.60      0.53      0.54      4626\n",
      "weighted avg       0.91      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - CNN Undersampling\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4366\n",
      "           1       0.17      0.04      0.07       260\n",
      "\n",
      "    accuracy                           0.93      4626\n",
      "   macro avg       0.56      0.51      0.52      4626\n",
      "weighted avg       0.90      0.93      0.92      4626\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for Model in Models :\n",
    "\n",
    "    model_CNN = Model.fit(X_train_CNN, y_train_CNN)\n",
    "    y_pred_CNN = model_CNN.predict(X_test_encoded)\n",
    "    print(f\"{type(Model)} - CNN Undersampling\")\n",
    "    print(\"==========================================================\")\n",
    "    print()    \n",
    "    print(classification_report(y_test_flattened, y_pred_CNN, labels=[0,1]))\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models with SMOTETomek Hybrid Balancing\n",
    "### Like undersampling, hybrid sampling on fraud data is just including undersampling which didn't work, effectively \"watering down\" the oversampling.  However, it turns out \"watering down\" is not that simple, as this hybrid method resulted in one of our three best results.  Still, we attribute this result to the oversampling component of the hybridization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.62      0.76      4366\n",
      "           1       0.12      0.92      0.22       260\n",
      "\n",
      "    accuracy                           0.63      4626\n",
      "   macro avg       0.56      0.77      0.49      4626\n",
      "weighted avg       0.94      0.63      0.73      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83      4366\n",
      "           1       0.09      0.46      0.15       260\n",
      "\n",
      "    accuracy                           0.72      4626\n",
      "   macro avg       0.52      0.59      0.49      4626\n",
      "weighted avg       0.91      0.72      0.79      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      4366\n",
      "           1       0.13      0.23      0.17       260\n",
      "\n",
      "    accuracy                           0.87      4626\n",
      "   macro avg       0.54      0.57      0.55      4626\n",
      "weighted avg       0.91      0.87      0.89      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4366\n",
      "           1       0.38      0.06      0.10       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.66      0.53      0.53      4626\n",
      "weighted avg       0.91      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._forest.ExtraTreesClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4366\n",
      "           1       0.31      0.06      0.10       260\n",
      "\n",
      "    accuracy                           0.94      4626\n",
      "   macro avg       0.63      0.52      0.53      4626\n",
      "weighted avg       0.91      0.94      0.92      4626\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88      4366\n",
      "           1       0.16      0.60      0.25       260\n",
      "\n",
      "    accuracy                           0.79      4626\n",
      "   macro avg       0.56      0.70      0.56      4626\n",
      "weighted avg       0.93      0.79      0.84      4626\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - SMOTETomek Hybrid Balancing\n",
      "==========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      4366\n",
      "           1       0.15      0.50      0.22       260\n",
      "\n",
      "    accuracy                           0.81      4626\n",
      "   macro avg       0.56      0.66      0.56      4626\n",
      "weighted avg       0.92      0.81      0.85      4626\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for Model in Models :\n",
    "\n",
    "    model_smote_tomek = Model.fit(X_train_smote_tomek, y_train_smote_tomek)\n",
    "    y_pred_smote_tomek = model_smote_tomek.predict(X_test_encoded)\n",
    "\n",
    "    print(f\"{type(Model)} - SMOTETomek Hybrid Balancing\")\n",
    "    print(\"==========================================================\")\n",
    "    print()    \n",
    "    print(classification_report(y_test_flattened, y_pred_smote_tomek, labels=[0,1]))\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the encoded data for use by the python model training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the encoded data to CSV files for use by the python script\n",
    "X_train_encoded.to_csv(\"data/encoded_training_data.csv\", index=False, header=False)\n",
    "X_test_encoded.to_csv(\"data/encoded_test_data.csv\", index=False, header=False)\n",
    "pd.DataFrame(y_train).to_csv(\"data/encoded_training_fraud_scoring.csv\", index=False, header=False)\n",
    "pd.DataFrame(y_test).to_csv(\"data/encoded_test_fraud_scoring.csv\", index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
